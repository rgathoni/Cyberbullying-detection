{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69cbefb6",
   "metadata": {},
   "source": [
    "# Notebook 2: Model Training and Evaluation\n",
    "\n",
    "This notebook focuses on training a machine learning model using the preprocessed data from Notebook 1. We will:\n",
    "1. Load the cleaned data.\n",
    "2. Split the data into training and testing sets.\n",
    "3. Build a `scikit-learn` pipeline for vectorization and classification.\n",
    "4. Train the model.\n",
    "5. Evaluate its performance using key metrics (Precision, Recall, F1-Score) and a confusion matrix.\n",
    "6. Perform a qualitative error analysis to understand its weaknesses.\n",
    "7. Save the final trained model for future use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e353ebd",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b671e0fa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "sns.set_context('talk')\n",
    "\n",
    "# Load the processed dataset\n",
    "try:\n",
    "    df = pd.read_csv('../data/cleaned_data.csv')\n",
    "    print(\"Processed dataset loaded successfully!\")\n",
    "    df.dropna(subset=['processed_text', 'bullying_label'], inplace=True)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: `data/cleaned_data.csv` not found.\")\n",
    "    print(\"Please run Notebook 1 or `src/preprocess.py` first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788955a4",
   "metadata": {},
   "source": [
    "## 2. Prepare Data for Modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068da8cb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define our features (X) and target (y)\n",
    "X = df['processed_text']\n",
    "y = df['bullying_label']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "# We use stratify=y to ensure the class distribution is the same in both train and test sets, which is crucial for imbalanced datasets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e81b7a",
   "metadata": {},
   "source": [
    "## 3. Build and Train the Model Pipeline\n",
    "\n",
    "We will use a `Pipeline` to chain our vectorizer and classifier together. This is a best practice as it prevents data leakage from the test set during the feature engineering phase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a4cfe6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "triage_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1, 2))),\n",
    "    ('clf', LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000, C=1.0))\n",
    "])\n",
    "\n",
    "# Train the pipeline on the training data\n",
    "print(\"Training the model...\")\n",
    "triage_pipeline.fit(X_train, y_train)\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dc9262",
   "metadata": {},
   "source": [
    "**Pipeline Components:**\n",
    "- **TfidfVectorizer**: Converts text into numerical features, considering both unigrams and bigrams (`ngram_range=(1, 2)`) to capture short phrases.\n",
    "- **LogisticRegression**: A robust and interpretable linear model. We use `class_weight='balanced'` to counteract class imbalance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdd93f7",
   "metadata": {},
   "source": [
    "## 4. Evaluate Model Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dbd61b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = triage_pipeline.predict(X_test)\n",
    "\n",
    "# Print a detailed classification report\n",
    "print(\"--- Classification Report ---\")\n",
    "report = classification_report(y_test, y_pred, target_names=['Not Bullying', 'Bullying'])\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fba7f7",
   "metadata": {},
   "source": [
    "The F1-score for the **Bullying** class is our key metric. It provides a balance between Precision (minimizing false positives) and Recall (minimizing false negatives).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99c3aa3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Generate and display the confusion matrix\n",
    "print(\"--- Confusion Matrix ---\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Not Bullying', 'Bullying'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "disp.plot(ax=ax, cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8cc87a",
   "metadata": {},
   "source": [
    "**Interpreting the Matrix:**\n",
    "- **Top-Left (True Negative):** Correctly identified as 'Not Bullying'.\n",
    "- **Bottom-Right (True Positive):** Correctly identified as 'Bullying'.\n",
    "- **Top-Right (False Positive):** Mistakenly flagged as 'Bullying'. **(We want this to be low)**\n",
    "- **Bottom-Left (False Negative):** Missed a case of 'Bullying'. **(We also want this to be low)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dba4be",
   "metadata": {},
   "source": [
    "## 5. Qualitative Error Analysis\n",
    "\n",
    "Metrics are useful, but looking at the actual errors our model makes provides deeper insight into its limitations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eb2a97",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame to see the errors\n",
    "error_df = pd.DataFrame({'text': X_test, 'actual': y_test, 'predicted': y_pred})\n",
    "error_df = error_df[error_df['actual'] != error_df['predicted']]\n",
    "\n",
    "# Show some False Positives (predicted Bullying, but was Not Bullying)\n",
    "print(\"--- Sample False Positives ---\")\n",
    "fp_samples = error_df[error_df['actual'] == 0].head(5)\n",
    "for i, row in fp_samples.iterrows():\n",
    "    print(f\"Text: {row['text']}\\n\")\n",
    "\n",
    "# Show some False Negatives (predicted Not Bullying, but was Bullying)\n",
    "print(\"\\n--- Sample False Negatives ---\")\n",
    "fn_samples = error_df[error_df['actual'] == 1].head(5)\n",
    "for i, row in fn_samples.iterrows():\n",
    "    print(f\"Text: {row['text']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05ca990",
   "metadata": {},
   "source": [
    "**Analysis of Errors:**\n",
    "The **False Positives** often involve aggressive language or profanity used in a non-bullying context (e.g., excitement, friendly banter). This is a classic challenge for NLP models.\n",
    "\n",
    "The **False Negatives** are more concerning. They often involve subtle sarcasm, exclusion, or targeted attacks that don't use obvious keywords. This is precisely where a more advanced, context-aware model like DistilBERT or an LLM would be needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9366ba",
   "metadata": {},
   "source": [
    "## 6. Save the Final Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe9938b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create a directory for the models if it doesn't exist\n",
    "model_dir = '../models'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Save the entire pipeline object\n",
    "model_path = os.path.join(model_dir, 'triage_model_pipeline.joblib')\n",
    "joblib.dump(triage_pipeline, model_path)\n",
    "\n",
    "print(f\"Model pipeline saved successfully to: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b14b514",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "We have successfully trained and evaluated a Logistic Regression model that serves as a strong baseline for cyberbullying detection. Its performance is respectable, and its weaknesses (difficulty with nuance and sarcasm) clearly point toward the next steps outlined in the project report: implementing a more advanced deep learning model to handle the ambiguous cases this Triage Model struggles with.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
